{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pennylane import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane_qiskit import IBMQDevice\n",
    "from pennylane_qiskit import BasicAerDevice\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out CSV and sets/samples creation\n",
    "\n",
    "df = pd.read_csv('fraud_detection_bank_dataset.csv', sep=',')\n",
    "df = df.astype(float)\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df_sample = df.sample(2000)\n",
    "train,test = train_test_split(df_sample, test_size=0.30, random_state=10)\n",
    "train_set = train\n",
    "test_set = test\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 1989 to 15622\n",
      "Columns: 113 entries, col_0 to targets\n",
      "dtypes: float64(113)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Review the information related to the dataframe\n",
    "\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.363500</td>\n",
       "      <td>319.388500</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>2.431500</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>2.415000</td>\n",
       "      <td>3.363500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>45.240000</td>\n",
       "      <td>0.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.707491</td>\n",
       "      <td>697.144656</td>\n",
       "      <td>5.222818</td>\n",
       "      <td>11.643285</td>\n",
       "      <td>1.393115</td>\n",
       "      <td>4.840697</td>\n",
       "      <td>2.983325</td>\n",
       "      <td>13.707491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089191</td>\n",
       "      <td>0.478329</td>\n",
       "      <td>0.059072</td>\n",
       "      <td>0.469785</td>\n",
       "      <td>0.405257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227058</td>\n",
       "      <td>0.354928</td>\n",
       "      <td>64.505317</td>\n",
       "      <td>0.437366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>12179.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             col_0         col_1        col_2        col_3        col_4  \\\n",
       "count  2000.000000   2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      3.363500    319.388500     0.447000     2.431500     0.098500   \n",
       "std      13.707491    697.144656     5.222818    11.643285     1.393115   \n",
       "min       0.000000      0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     39.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000    105.000000     0.000000     1.000000     0.000000   \n",
       "75%       2.000000    302.000000     0.000000     2.000000     0.000000   \n",
       "max     342.000000  12179.000000   194.000000   360.000000    54.000000   \n",
       "\n",
       "             col_5        col_6        col_7   col_8   col_9  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.0  2000.0  ...   \n",
       "mean      1.058000     2.415000     3.363500     0.0     0.0  ...   \n",
       "std       4.840697     2.983325    13.707491     0.0     0.0  ...   \n",
       "min       0.000000    -1.000000     0.000000     0.0     0.0  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.0     0.0  ...   \n",
       "50%       0.000000     2.000000     0.000000     0.0     0.0  ...   \n",
       "75%       1.000000     6.000000     2.000000     0.0     0.0  ...   \n",
       "max     161.000000     8.000000   342.000000     0.0     0.0  ...   \n",
       "\n",
       "           col_103      col_104      col_105      col_106      col_107  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.007000     0.354000     0.003500     0.328500     0.207000   \n",
       "std       0.089191     0.478329     0.059072     0.469785     0.405257   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       2.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       col_108      col_109      col_110      col_111      targets  \n",
       "count   2000.0  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean       0.0     0.054500     0.033000    45.240000     0.257500  \n",
       "std        0.0     0.227058     0.354928    64.505317     0.437366  \n",
       "min        0.0     0.000000     0.000000     0.000000     0.000000  \n",
       "25%        0.0     0.000000     0.000000     5.000000     0.000000  \n",
       "50%        0.0     0.000000     0.000000    20.000000     0.000000  \n",
       "75%        0.0     0.000000     0.000000    62.000000     1.000000  \n",
       "max        0.0     1.000000    11.000000   747.000000     1.000000  \n",
       "\n",
       "[8 rows x 113 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of the description of the dataframe related to fixed parameters\n",
    "\n",
    "df_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 113)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 113)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.astype(float)\n",
    "test_set = test_set.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set\n",
    "y_train = train_set[['targets']]\n",
    "x_test = test_set\n",
    "y_test = test_set[['targets']]\n",
    "\n",
    "x_train.drop(['targets'],axis = 1,inplace = True)\n",
    "x_test.drop(['targets'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targets\n",
       "0.0        74.142857\n",
       "1.0        25.857143\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train classes distribution\n",
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targets\n",
       "0.0        74.5\n",
       "1.0        25.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing classes distribution\n",
    "y_test.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (1400, 112)\n",
      "Test Shape : (600, 112)\n"
     ]
    }
   ],
   "source": [
    "#Train and test shape\n",
    "print(\"Train Shape: {}\\nTest Shape : {}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension definition\n",
    "n_dim = 2\n",
    "\n",
    "#PCA application for dimensionality reduction\n",
    "pca = PCA(n_components=n_dim, svd_solver='full')\n",
    "pca.fit(x_train)\n",
    "x_train_pca = pca.transform(x_train)\n",
    "pca.fit(x_test)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99997061  0.00766626]\n",
      " [-0.99995283 -0.00971271]\n",
      " [-0.99994675 -0.01032004]\n",
      " ...\n",
      " [-0.99744184  0.07148264]\n",
      " [-0.99997117 -0.00759275]\n",
      " [ 0.99997905 -0.0064727 ]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization of train\n",
    "data = normalize(x_train_pca)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.999983   -0.00583141]\n",
      " [-0.99998912 -0.00466432]\n",
      " [ 0.99998742 -0.00501584]\n",
      " ...\n",
      " [-0.99999334 -0.00364874]\n",
      " [-0.99999382 -0.00351611]\n",
      " [-0.99999344 -0.00362247]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization of test\n",
    "x_test = normalize(x_test)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle Encoding\n",
    "\n",
    "num_qubits = data.shape[1]\n",
    "\n",
    "dev = qml.device('default.qubit', wires = num_qubits, shots = 256)\n",
    "#dev = qml.device('qiskit.ibmq', wires = num_qubits, backend='ibmq_manila', provider=provider)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(parameters, data):\n",
    "    # Apply Hadamards to all qubits in the circuit\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00496714 -0.00138264  0.00647689]\n",
      "  [ 0.0152303  -0.00234153 -0.00234137]]\n",
      "\n",
      " [[ 0.01579213  0.00767435 -0.00469474]\n",
      "  [ 0.0054256  -0.00463418 -0.0046573 ]]\n",
      "\n",
      " [[ 0.00241962 -0.0191328  -0.01724918]\n",
      "  [-0.00562288 -0.01012831  0.00314247]]\n",
      "\n",
      " [[-0.00908024 -0.01412304  0.01465649]\n",
      "  [-0.00225776  0.00067528 -0.01424748]]\n",
      "\n",
      " [[-0.00544383  0.00110923 -0.01150994]\n",
      "  [ 0.00375698 -0.00600639 -0.00291694]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.03125, requires_grad=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(weights_init, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [tensor(-0.99997061, requires_grad=False), tensor(0.00766626, requires_grad=False)], Y = -1\n",
      "X = [tensor(-0.99995283, requires_grad=False), tensor(-0.00971271, requires_grad=False)], Y = -1\n",
      "X = [tensor(-0.99994675, requires_grad=False), tensor(-0.01032004, requires_grad=False)], Y = -1\n",
      "X = [tensor(0.99467012, requires_grad=False), tensor(-0.10310845, requires_grad=False)], Y = -1\n",
      "X = [tensor(-0.99995653, requires_grad=False), tensor(-0.00932417, requires_grad=False)], Y = -1\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(y_train.values[:,0] * 2 - np.ones(len(y_train.values[:,0])), requires_grad = False)  # shift label from {0, 1} to {-1, 1}\n",
    "X = np.array(data, requires_grad=False)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "#opt = AdagradOptimizer(stepsize=0.01, eps=1e-08)\n",
    "#opt = GradientDescentOptimizer(stepsize=0.01)\n",
    "#opt = RMSPropOptimizer(stepsize=0.01, decay=0.9, eps=1e-08)\n",
    "#opt = NesterovMomentumOptimizer(stepsize=0.01, momentum=0.9)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.8142133 | Accuracy: 0.7371429 \n",
      "New best\n",
      "Iter:     2 | Cost: 0.7492751 | Accuracy: 0.7414286 \n",
      "Iter:     3 | Cost: 0.7481851 | Accuracy: 0.7414286 \n",
      "Iter:     4 | Cost: 0.8636719 | Accuracy: 0.6300000 \n",
      "Iter:     5 | Cost: 0.8025046 | Accuracy: 0.7292857 \n",
      "Iter:     6 | Cost: 0.7605707 | Accuracy: 0.7414286 \n",
      "Iter:     7 | Cost: 0.7525719 | Accuracy: 0.7414286 \n",
      "Iter:     8 | Cost: 0.7460470 | Accuracy: 0.7414286 \n",
      "Iter:     9 | Cost: 0.7504315 | Accuracy: 0.7414286 \n",
      "Iter:    10 | Cost: 0.7668446 | Accuracy: 0.7414286 \n",
      "Iter:    11 | Cost: 0.7903816 | Accuracy: 0.7414286 \n",
      "Iter:    12 | Cost: 0.7583754 | Accuracy: 0.7414286 \n",
      "Iter:    13 | Cost: 0.7435417 | Accuracy: 0.7414286 \n",
      "Iter:    14 | Cost: 0.8243844 | Accuracy: 0.7314286 \n",
      "Iter:    15 | Cost: 0.9313670 | Accuracy: 0.4850000 \n",
      "Iter:    16 | Cost: 0.9178925 | Accuracy: 0.4914286 \n",
      "Iter:    17 | Cost: 0.8572023 | Accuracy: 0.7028571 \n",
      "Iter:    18 | Cost: 0.7702813 | Accuracy: 0.7414286 \n",
      "Iter:    19 | Cost: 0.7740805 | Accuracy: 0.7414286 \n",
      "Iter:    20 | Cost: 0.9743450 | Accuracy: 0.7414286 \n",
      "Iter:    21 | Cost: 1.0429149 | Accuracy: 0.7414286 \n",
      "Iter:    22 | Cost: 1.0326060 | Accuracy: 0.7414286 \n",
      "Iter:    23 | Cost: 0.8991914 | Accuracy: 0.7414286 \n",
      "Iter:    24 | Cost: 0.7709373 | Accuracy: 0.7414286 \n",
      "Iter:    25 | Cost: 0.7350728 | Accuracy: 0.7414286 \n",
      "Iter:    26 | Cost: 0.8537272 | Accuracy: 0.6492857 \n",
      "Iter:    27 | Cost: 0.8607656 | Accuracy: 0.6292857 \n",
      "Iter:    28 | Cost: 0.7637338 | Accuracy: 0.7414286 \n",
      "Iter:    29 | Cost: 0.7567716 | Accuracy: 0.7414286 \n",
      "Iter:    30 | Cost: 0.8052604 | Accuracy: 0.7414286 \n",
      "Iter:    31 | Cost: 0.8293959 | Accuracy: 0.7414286 \n",
      "Iter:    32 | Cost: 0.8172791 | Accuracy: 0.7414286 \n",
      "Iter:    33 | Cost: 0.7971415 | Accuracy: 0.7414286 \n",
      "Iter:    34 | Cost: 0.7733342 | Accuracy: 0.7414286 \n",
      "Iter:    35 | Cost: 0.7615322 | Accuracy: 0.7414286 \n",
      "Iter:    36 | Cost: 0.7589089 | Accuracy: 0.7414286 \n",
      "Iter:    37 | Cost: 0.7902360 | Accuracy: 0.7414286 \n",
      "Iter:    38 | Cost: 0.7981693 | Accuracy: 0.7414286 \n",
      "Iter:    39 | Cost: 0.8453596 | Accuracy: 0.7414286 \n",
      "Iter:    40 | Cost: 0.8964028 | Accuracy: 0.7414286 \n",
      "Iter:    41 | Cost: 0.9092458 | Accuracy: 0.7414286 \n",
      "Iter:    42 | Cost: 0.7900895 | Accuracy: 0.7414286 \n",
      "Iter:    43 | Cost: 0.7414881 | Accuracy: 0.7414286 \n",
      "Iter:    44 | Cost: 0.7478766 | Accuracy: 0.7414286 \n",
      "Iter:    45 | Cost: 0.7826977 | Accuracy: 0.7414286 \n",
      "Iter:    46 | Cost: 0.7973897 | Accuracy: 0.7350000 \n",
      "Iter:    47 | Cost: 0.8330424 | Accuracy: 0.6828571 \n",
      "Iter:    48 | Cost: 0.8554368 | Accuracy: 0.6378571 \n",
      "Iter:    49 | Cost: 0.8663994 | Accuracy: 0.5985714 \n",
      "Iter:    50 | Cost: 0.8770845 | Accuracy: 0.5657143 \n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "\n",
    "for it in range(50):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "    if accuracy(Y, predictions) > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = accuracy(Y, predictions)\n",
    "        print('New best')\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.array(y_test.values[:,0] * 2 - np.ones(len(y_test.values[:,0])), requires_grad = False)\n",
    "Xte = np.array(normalize(x_test), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.7525858753099877, Accuracy: 74.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
    "acc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions  Test\n",
       "0          -1.0  -1.0\n",
       "1          -1.0  -1.0\n",
       "2          -1.0   1.0\n",
       "3          -1.0  -1.0\n",
       "4          -1.0  -1.0\n",
       "..          ...   ...\n",
       "595        -1.0   1.0\n",
       "596        -1.0  -1.0\n",
       "597        -1.0  -1.0\n",
       "598        -1.0   1.0\n",
       "599        -1.0  -1.0\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((predictions, Yte), ('Predictions', 'Test')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 32m-11s\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "totaltime = end - start\n",
    "\n",
    "mins = int(np.round(totaltime % 60))\n",
    "secs = int(np.round((totaltime % 60 - mins) * 60))\n",
    "\n",
    "print(f'Execution time: {mins}m{secs}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.74      0.85       600\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.50      0.37      0.43       600\n",
      "weighted avg       1.00      0.74      0.85       600\n",
      "\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.745\n",
      "[[447 153]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report and important metrics\n",
    "\n",
    "print(metrics.classification_report(predictions,Yte))\n",
    "print(metrics.precision_score(predictions,Yte))\n",
    "print(metrics.recall_score(predictions,Yte))\n",
    "print(metrics.f1_score(predictions,Yte))\n",
    "print(metrics.balanced_accuracy_score(predictions,Yte))\n",
    "print(metrics.confusion_matrix(predictions,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
